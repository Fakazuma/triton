version: '1.2'
services:
  triton_hf_transformer_example:
    command: ["--model-repository=/models", "--log-info=1"]
    build: 01_huggingface_transformer
    shm_size: '64gb'
#    restart: unless-stopped
    ports:
      - 8500:8000
      - 8501:8001
      - 8502:8002
    volumes:
      - ./:/workspace
      - ./model_repository:/models
      - ./assets:/assets
    environment:
      - LC_ALL=C.UTF-8
      - LANG=C.UTF-8
    deploy:
      resources:
        limits:
          cpus: '10'
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ]
              capabilities: [ gpu ]